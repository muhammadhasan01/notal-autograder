{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn.metrics import mean_absolute_error, confusion_matrix, ConfusionMatrixDisplay"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "EXAM_NAMES = ['Kuis 2', 'UTS']\n",
    "EXAM_NUMBERS = {\n",
    "    'Kuis 2': ['IA', 'IB', 'IC'],\n",
    "    'UTS': ['IA', 'IB']\n",
    "}\n",
    "EXAMS = []\n",
    "for exam_name in EXAM_NAMES:\n",
    "    for exam_number in EXAM_NUMBERS[exam_name]:\n",
    "        EXAMS.append((exam_name, exam_number))\n",
    "\n",
    "LB = {\n",
    "    'All': 0.6562801963,\n",
    "    'Kuis 2 IA': 0.1447276516,\n",
    "    'Kuis 2 IB': 0.3178719202,\n",
    "    'Kuis 2 IC': 0.6346878475,\n",
    "    'UTS IA': 0.5107134316,\n",
    "    'UTS IB': 0.4047760493\n",
    "}\n",
    "\n",
    "X_AXIS = 'nilai autograder'\n",
    "Y_AXIS = 'nilai manual'\n",
    "EPS = 0.001\n",
    "\n",
    "import os \n",
    "import sys\n",
    "\n",
    "module_path = os.path.abspath(os.path.join('..')) \n",
    "if module_path not in sys.path: \n",
    "    sys.path.append(module_path) \n",
    "    \n",
    "from grader.src.ged.classes.general_cost_function import RelabelMethod\n",
    "from grader.src.grader import Grader, GraphPreprocessType\n",
    "\n",
    "REAL_GRADE_FILENAME = 'Real Results.csv' \n",
    "AFILE_PREFIX = 'Grade_'\n",
    "\n",
    "real_dataframe = pd.read_csv(REAL_GRADE_FILENAME)\n",
    "dataframes = {}\n",
    "for relabel_method in RelabelMethod.__iter__():\n",
    "    for graph_preprocess_type in GraphPreprocessType.__iter__():\n",
    "        filename = f'Train_{relabel_method.name}_{graph_preprocess_type.name}.csv'\n",
    "        if filename not in os.listdir('./'):\n",
    "            continue\n",
    "#         dataframes[filename] = pd.read_csv(filename).rename(columns={'grade': 'nilai autograder'})\n",
    "        dataframes[filename] = pd.read_csv(filename)\n",
    "        dataframes[filename] = pd.merge(dataframes[filename], real_dataframe, on=['nim', 'exam_name', 'number'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "RATE = 0.0001\n",
    "\n",
    "# y = sigma x_i * w_i\n",
    "# dE / dw_i = x_i * (y - t)\n",
    "# delta w_i = -rate * (dE/dw_i) = -rate * x_i * (y - t)\n",
    "X1_LABEL = 'total_node_cost'\n",
    "X2_LABEL = 'total_edge_cost'\n",
    "T_LABEL = 'nilai manual'\n",
    "\n",
    "def normalized(w1, w2):\n",
    "    norm = math.sqrt(w1 * w1 + w2 * w2)\n",
    "    return w1 / norm, w2 / norm\n",
    "\n",
    "def train(df, epoch=100):\n",
    "    w1 = 1.0\n",
    "    w2 = 1.0\n",
    "    for cur_epoch in range(epoch):\n",
    "        for id, row in df.iterrows():\n",
    "            count1 = row['node_count']\n",
    "            count2 = row['edge_count']\n",
    "            \n",
    "            x1 = row[X1_LABEL]\n",
    "            x2 = row[X2_LABEL]\n",
    "            t = (1.0 - (row[T_LABEL] / 100)) * (count1 * w1 + count2 * w2)\n",
    "            \n",
    "            y = x1 * w1 + x2 * w2\n",
    "            delta_w1 = -RATE * x1 * (y - t)\n",
    "            delta_w2 = -RATE * x2 * (y - t)\n",
    "            \n",
    "            w1 += delta_w1\n",
    "            w2 += delta_w2\n",
    "            w1, w2 = normalized(w1, w2)\n",
    "            \n",
    "    return w1, w2\n",
    "\n",
    "results = {}\n",
    "for filename, df in dataframes.items():\n",
    "    w1, w2 = train(df, 200)\n",
    "    new_row = [100 * (1 - (row[X1_LABEL] * w1 + row[X2_LABEL] * w2)) / (row['node_count'] * w1 + row['edge_count'] * w2) for id, row in df.iterrows()]\n",
    "    df['nilai autograder'] = new_row\n",
    "    corr = df.corr()\n",
    "    results[filename] = {\n",
    "        'weight': (w1, w2),\n",
    "        'old_correlation': corr[\"grade\"][Y_AXIS],\n",
    "        'new_correlation': corr[X_AXIS][Y_AXIS]\n",
    "    }\n",
    "    \n",
    "for filename, stats in results.items():\n",
    "    print(f'{filename} training result\\n--------------')\n",
    "    for k, v in stats.items():\n",
    "        print(f'{k}: {v}')\n",
    "    print('--------------\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Result \n",
    "\n",
    "Starts with weight (1, 1)\n",
    "```\n",
    "Train_NONE_UNCOLLAPSE.csv training result\n",
    "--------------\n",
    "weight: (0.8257784952978421, 0.5639945715196486)\n",
    "old_correlation: 0.7237943416739918\n",
    "new_correlation: 0.7309536273785884\n",
    "--------------\n",
    "\n",
    "Train_NONE_COLLAPSE.csv training result\n",
    "--------------\n",
    "weight: (0.48785594253967823, 0.8729241543964299)\n",
    "old_correlation: 0.686587182493469\n",
    "new_correlation: 0.6856247758236598\n",
    "--------------\n",
    "\n",
    "Train_NONE_PROPAGATE_BRANCHING.csv training result\n",
    "--------------\n",
    "weight: (0.42704726637701995, 0.9042293029314603)\n",
    "old_correlation: 0.6493976092819717\n",
    "new_correlation: 0.6492057126073356\n",
    "--------------\n",
    "\n",
    "Train_BOOLEAN_COUNT_UNCOLLAPSE.csv training result\n",
    "--------------\n",
    "weight: (0.8584438636207447, 0.5129075287143761)\n",
    "old_correlation: 0.7236863160356296\n",
    "new_correlation: 0.7292914890584136\n",
    "--------------\n",
    "\n",
    "Train_BOOLEAN_COUNT_COLLAPSE.csv training result\n",
    "--------------\n",
    "weight: (0.8565880656045796, 0.5160008583944453)\n",
    "old_correlation: 0.6377400969554124\n",
    "new_correlation: 0.678042439961036\n",
    "--------------\n",
    "\n",
    "Train_BOOLEAN_COUNT_PROPAGATE_BRANCHING.csv training result\n",
    "--------------\n",
    "weight: (0.5855415415769536, 0.8106424014864289)\n",
    "old_correlation: 0.6363141615448296\n",
    "new_correlation: 0.6520778501898457\n",
    "--------------\n",
    "\n",
    "Train_COUNTER_COLLAPSE.csv training result\n",
    "--------------\n",
    "weight: (0.8774999661590893, 0.47957669813158876)\n",
    "old_correlation: 0.655214792911339\n",
    "new_correlation: 0.6941486571893627\n",
    "--------------\n",
    "\n",
    "Train_COUNTER_PROPAGATE_BRANCHING.csv training result\n",
    "--------------\n",
    "weight: (0.6071869661112416, 0.7945589897450196)\n",
    "old_correlation: 0.6408816580522574\n",
    "new_correlation: 0.6552280575384303\n",
    "--------------\n",
    "\n",
    "Train_DAMERAU_LD_COLLAPSE.csv training result\n",
    "--------------\n",
    "weight: (0.8771657473231458, 0.480187725502253)\n",
    "old_correlation: 0.6337564587828098\n",
    "new_correlation: 0.6819078442276093\n",
    "--------------\n",
    "\n",
    "Train_DAMERAU_LD_PROPAGATE_BRANCHING.csv training result\n",
    "--------------\n",
    "weight: (0.6139905931782683, 0.789313341765232)\n",
    "old_correlation: 0.646898025402812\n",
    "new_correlation: 0.661430477139439\n",
    "--------------\n",
    "\n",
    "Train_EXACT_COLLAPSE.csv training result\n",
    "--------------\n",
    "weight: (0.922103988285686, 0.38694215948592586)\n",
    "old_correlation: 0.6327693058925489\n",
    "new_correlation: 0.6726393957117593\n",
    "--------------\n",
    "\n",
    "Train_EXACT_PROPAGATE_BRANCHING.csv training result\n",
    "--------------\n",
    "weight: (0.7543733917011383, 0.656445569634925)\n",
    "old_correlation: 0.6154178430154562\n",
    "new_correlation: 0.638491346018969\n",
    "--------------\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": ".venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
